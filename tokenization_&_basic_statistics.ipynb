{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UTNrifqQgEm3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1"
      ],
      "metadata": {
        "id": "DDKRv-BEf8UL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Installation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> *   NLTK library\n",
        "\n",
        "\n",
        "> *   NLTK data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UTNrifqQgEm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA0yysY7gXQ7",
        "outputId": "5b82ae45-7e12-4c94-a5c4-302e544e8b9d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Consider the utterance “Hello world. How are you?”\n"
      ],
      "metadata": {
        "id": "QZRDNKz0gfH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utterance = \"Hello World. How are you?\""
      ],
      "metadata": {
        "id": "04rhhZwynrt-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Split the utterance into word tokens"
      ],
      "metadata": {
        "id": "4cwnJz-Ggmr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "tokens = nltk.word_tokenize(utterance)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z46jRKIboF09",
        "outputId": "d0c16f71-3b48-4141-ea67-edb9fb8c5537"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'World', '.', 'How', 'are', 'you', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. How many tokens are there?"
      ],
      "metadata": {
        "id": "RVz9f3JvgzOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"There are {len(tokens)} in the phrase: {utterance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ5m0b5YoU4X",
        "outputId": "526d81ef-7d0f-4d19-c548-b10d460c7e87"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 7 in the phrase: Hello World. How are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Open the file Alice’s Adventures in Wonderland by Lewis Carroll (alice.txt)"
      ],
      "metadata": {
        "id": "B73sFuAjg3IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"alice.txt\", \"r\") as file:\n",
        "    alice = file.read()"
      ],
      "metadata": {
        "id": "qU_wk2jtof2n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Divide the text into tokens and count them"
      ],
      "metadata": {
        "id": "Jl352_y-g7bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(alice)\n",
        "tokens[:10] #just to show some"
      ],
      "metadata": {
        "id": "NfKgvjKwpkSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e614b53b-51b1-471a-b7e0-738162e8d764"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Project',\n",
              " 'Gutenberg',\n",
              " '’',\n",
              " 's',\n",
              " 'Alice',\n",
              " '’',\n",
              " 's',\n",
              " 'Adventures',\n",
              " 'in',\n",
              " 'Wonderland']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"There are {len(tokens)} in the book: Alice in wonderland\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EewBZyK0pk9e",
        "outputId": "1839407e-f0c9-4147-b1b3-6c80b9a09186"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 38349 in the book: Alice in wonderland\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Calculate the ratio between number of tokens and vocabulary **(lexical diversity)**"
      ],
      "metadata": {
        "id": "xsOi3O-WhG8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vocabulary\n",
        "vocab_len = len(set(tokens))\n"
      ],
      "metadata": {
        "id": "NLA1IIKLpzpU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lexical_diversity =  len(tokens)/vocab_len\n",
        "print(f\"lexical_diversity index of the Alice's Adventures in Wonderland is of: {lexical_diversity}, Which means that each word appears {lexical_diversity} times in the book\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcBBqktnqElx",
        "outputId": "d683c58e-e79d-4d9e-e6ae-bf060ce1c242"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical_diversity index of the Alice's Adventures in Wonderland is of: 10.311642914762032, Which means that each word appears 10.311642914762032 times in the book\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Consider the utterance “Jane lent $100 to Peter early this morning.”"
      ],
      "metadata": {
        "id": "TRKRYVYFh5cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utterance = 'Jane lent $100 to Peter early this morning.'"
      ],
      "metadata": {
        "id": "-VECkPHoh9Av"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitted = utterance.split()\n",
        "splitted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3ft4T7Fq3sw",
        "outputId": "f36b07dd-6257-4efe-fd72-4f86851ad01d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jane', 'lent', '$100', 'to', 'Peter', 'early', 'this', 'morning.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = nltk.word_tokenize(utterance)\n",
        "tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-20M1Iq-gr",
        "outputId": "015f43af-0054-49c0-be43-04e5e832aa03"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jane', 'lent', '$', '100', 'to', 'Peter', 'early', 'this', 'morning', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see nltks word_tokenize function splits the words more strictly, for example splitting $, which pythons split function does not."
      ],
      "metadata": {
        "id": "nTcTuvX-iGn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2"
      ],
      "metadata": {
        "id": "igEST_Xzia91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Open The Adventures of Sherlock Holmes by Arthur Conan Doyle"
      ],
      "metadata": {
        "id": "RDeoaMZ7ifuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/Adventures_Holmes.txt\", \"r\") as file:\n",
        "    holmes = file.read()"
      ],
      "metadata": {
        "id": "pwEeZfNLrKpQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Check the concordance of word “Sherlock”.\n",
        "\n",
        "\n",
        "> **concordance:** Study a particular word in its context\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbMHHhnQi4TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "holmes_tokenized = nltk.word_tokenize(holmes)\n",
        "from nltk import Text\n",
        "Text(holmes_tokenized).concordance(\"Sherlock\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbCuuEG2i0rH",
        "outputId": "a7ae70a9-1a00-4b52-bcca-7f866ff66f8a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 25 of 98 matches:\n",
            "﻿The Adventures of Sherlock Holmes by Arthur Conan Doyle Conte\n",
            "es I . A SCANDAL IN BOHEMIA I . To Sherlock Holmes she is always _the_ woman .\n",
            "ust such as I had pictured it from Sherlock Holmes ’ succinct description , bu\n",
            "ssing said : “ Good-night , Mister Sherlock Holmes. ” There were several peopl\n",
            "lly got it ! ” he cried , grasping Sherlock Holmes by either shoulder and look\n",
            "stepped from the brougham . “ Mr . Sherlock Holmes , I believe ? ” said she . \n",
            "ss for the Continent. ” “ What ! ” Sherlock Holmes staggered back , white with\n",
            ", the letter was superscribed to “ Sherlock Holmes , Esq . To be left till cal\n",
            "nd ran in this way : “ MY DEAR MR. SHERLOCK HOLMES , —You really did it very w\n",
            " of interest to the celebrated Mr. Sherlock Holmes . Then I , rather imprudent\n",
            " possess ; and I remain , dear Mr. Sherlock Holmes , “ Very truly yours , “ IR\n",
            "ia , and how the best plans of Mr. Sherlock Holmes were beaten by a woman ’ s \n",
            " I had called upon my friend , Mr. Sherlock Holmes , one day in the autumn of \n",
            "and discontent upon his features . Sherlock Holmes ’ quick eye took in my occu\n",
            "t as I have been telling you , Mr. Sherlock Holmes , ” said Jabez Wilson , mop\n",
            "e of this obliging youth ? ” asked Sherlock Holmes . “ His name is Vincent Spa\n",
            "IS DISSOLVED . October 9 , 1890. ” Sherlock Holmes and I surveyed this curt an\n",
            "d client carried on his business . Sherlock Holmes stopped in front of it with\n",
            " own stupidity in my dealings with Sherlock Holmes . Here I had heard what he \n",
            "” “ I think you will find , ” said Sherlock Holmes , “ that you will play for \n",
            "and I will follow in the second. ” Sherlock Holmes was not very communicative \n",
            "jump , and I ’ ll swing for it ! ” Sherlock Holmes had sprung out and seized t\n",
            "IDENTITY “ My dear fellow , ” said Sherlock Holmes as we sat on either side of\n",
            "ant-man behind a tiny pilot boat . Sherlock Holmes welcomed her with the easy \n",
            "nsult me in such a hurry ? ” asked Sherlock Holmes , with his finger-tips toge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Check the concordance of word “extreme”"
      ],
      "metadata": {
        "id": "xFC7_NmfjNMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Text(holmes_tokenized).concordance(\"extreme\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LTCwotpjcOF",
        "outputId": "880e4e95-027b-43df-8b1a-ae9634b650d4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 9 of 9 matches:\n",
            "may trust with a matter of the most extreme importance . If not , I should much\n",
            "ng red head , and the expression of extreme chagrin and discontent upon his fea\n",
            "ternately asserted itself , and his extreme exactness and astuteness represente\n",
            "e swing of his nature took him from extreme languor to devouring energy ; and ,\n",
            "olice reports realism pushed to its extreme limits , and yet the result is , it\n",
            "of an English provincial town . His extreme love of solitude in England suggest\n",
            "ion , and that in his haste and the extreme darkness he missed his path and wal\n",
            "for my coming at midnight , and his extreme anxiety lest I should tell anyone o\n",
            "like one who has been driven to the extreme limits of his reason . Then , sudde\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Look for similar words as “extreme”\n",
        "\n",
        "\n",
        "> **similar** words are words used in the same context as the specified token\n",
        "\n"
      ],
      "metadata": {
        "id": "gldbtPCKjfkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similars = Text(holmes_tokenized).similar(\"extreme\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG0MdDOYsZDN",
        "outputId": "9da23248-b39d-4229-ae26-417d6476b6f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dense gathering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Check the common contexts of “extreme” and “gathering”\n",
        "\n",
        "\n",
        "> **common contexts** method allows you to examine the contexts that are shared by two or more words"
      ],
      "metadata": {
        "id": "IRJK7UhEjtoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_contexts = Text(holmes_tokenized).common_contexts([\"extreme\",\"gathering\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5hdVHFrtzN-",
        "outputId": "5fe9524f-8b0b-475e-a461-588385ce0f8a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the_darkness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Calculate the collocations\n",
        "\n",
        "\n",
        "> collocation is a set of words usually appears together to convey semantic meanings"
      ],
      "metadata": {
        "id": "2BNcExnWlkgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collocations = Text(holmes_tokenized).collocations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVFqzef-uedN",
        "outputId": "993b5a17-458d-4b5d-f522-9f4590191942"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sherlock Holmes; Project Gutenberg-tm; said Holmes; St. Simon; Mr.\n",
            "Holmes; St. Clair; Baker Street; Project Gutenberg; Lord St.; United\n",
            "States; Literary Archive; young lady; Gutenberg-tm electronic; Irene\n",
            "Adler; electronic works; Miss Hunter; Archive Foundation; Gutenberg\n",
            "Literary; Briony Lodge; Neville St.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3"
      ],
      "metadata": {
        "id": "SB8DBQV7rf8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Open Moby Dick by Herman Melville"
      ],
      "metadata": {
        "id": "i3unnmHArl2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/moby_dick.txt\", \"r\") as file:\n",
        "    mobydick = file.read()"
      ],
      "metadata": {
        "id": "9POFrY6xvAmG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Use a dispersion plot to look for lexical patterns for positive and negative words\n",
        "\n",
        "\n",
        "\n",
        "> e.g., good, happy, strong, bad, sad, weak\n",
        "\n"
      ],
      "metadata": {
        "id": "e3t8UXZ2sOnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(mobydick)\n",
        "nltk.draw.dispersion_plot(mobydick, tokens, title='Lexical Dispersion Plot')"
      ],
      "metadata": {
        "id": "sFpB0DyXrxaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e3Dr2s-PsVMb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V53q2oD4r9kF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}