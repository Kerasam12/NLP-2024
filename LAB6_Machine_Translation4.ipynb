{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 6: Machine Translation. Italian to English with Seq2Seq RNNs with attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "1. Understand the seq2seq model architecture.\n",
    "2. Understand the attention mechanism.\n",
    "3. Implement a seq2seq model with attention mechanism for machine translation.\n",
    "4. Train the model on a Italian to English translation dataset.\n",
    "5. Translate Italian sentences to English.\n",
    "6. Evaluate the model using quantitative and qualitative evaluation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and SetUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up Wandb for Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mneildlf\u001b[0m (\u001b[33mnlp_2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/export/hhome/nlp2_g09/NLP-2024/wandb/run-20240413_190242-18yk63ek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp_2024/Machine_Translation/runs/18yk63ek' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/nlp_2024/Machine_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp_2024/Machine_Translation' target=\"_blank\">https://wandb.ai/nlp_2024/Machine_Translation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp_2024/Machine_Translation/runs/18yk63ek' target=\"_blank\">https://wandb.ai/nlp_2024/Machine_Translation/runs/18yk63ek</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp_2024/Machine_Translation/runs/18yk63ek?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fde77863950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"Machine_Translation\", entity=\"nlp_2024\", name=\"trial_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "Data can be found in our [github](https://github.com/Neilus03/NLP-2024/blob/main/data/eng-ita.txt).\n",
    "\n",
    "The dataset is a txt file that looks like this:\n",
    "\n",
    "```\n",
    "I haven't eaten pizza recently. Io non ho mangiato della pizza di recente.\n",
    "I haven't figured that out yet.\tNon l'ho ancora capito.\n",
    "Hello! Ciao!\n",
    "I saw you in the park with Tom.\tL'ho vista al parco con Tom.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Lang Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the start-of-sequence (SOS) and end-of-sequence (EOS) tokens\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "# Define the language class\n",
    "class Lang:\n",
    "    '''\n",
    "    Lang class to store the language vocabulary and word-to-index & index-to-word mappings.\n",
    "    It also stores the count of each word in the vocabulary\n",
    "    '''\n",
    "    def __init__(self, language):\n",
    "        self.language = language\n",
    "        self.word2index = {}  # dictionary to map words to indices\n",
    "        self.word2count = {}  # dictionary to count the occurrences of each word\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}  # dictionary to map indices to words\n",
    "        self.n_words = 2  # Count SOS and EOS tokens (initially 2)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        # Add each word in the sentence to the language\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        # Add a word to the language\n",
    "        if word not in self.word2index:\n",
    "            # If the word is not already in the dictionary, add it\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            # If the word is already in the dictionary, increment its count\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the Data a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(unicode_string):\n",
    "    # Convert unicode characters to ASCII\n",
    "    ascii_string = ''\n",
    "    for c in unicodedata.normalize('NFD', unicode_string): # NFD = Normalization Form Canonical Decomposition\n",
    "        if unicodedata.category(c) != 'Mn': # Mn = Nonspacing_Mark\n",
    "            ascii_string += c\n",
    "    return ascii_string\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    # Normalize the string by:\n",
    "    \n",
    "    # converting to lowercase,\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    #removing accents \n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #replacing non-alphabetic characters with spaces\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    #removing extra spaces\n",
    "    return s.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create read_data function, which reads the data from the file and returns the input and target language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(lang1, lang2, reverse=True, verbose=False):\n",
    "    '''\n",
    "    Read the data file, split the file into lines and split\n",
    "    lines into pairs. the `reverse` flag is used to translate from italian\n",
    "    to english instaed of the default english to italian\n",
    "    '''\n",
    "    if verbose:\n",
    "        print(\"Opening Data\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Create Lang instances\n",
    "    input_lang = Lang(lang1) if not reverse else Lang(lang2)\n",
    "    output_lang = Lang(lang2) if not reverse else Lang(lang1)\n",
    "    \n",
    "    # Leave pairs as they are if not reverse, otherwise reverse the pairs\n",
    "    pairs = [list(reversed(p)) for p in pairs] if reverse else pairs\n",
    "\n",
    "    # Return the language vocabulary and the pairs\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage of the read_data function, and how the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tom fece piangere sua sorella', 'tom made his sister cry'] ita eng\n",
      "['you re a prince tom', 'sei un principe tom'] eng ita\n"
     ]
    }
   ],
   "source": [
    "#Example usage of the read_data \n",
    "input_lang, output_lang, pairs = read_data('eng', 'ita', reverse=True, verbose=False)\n",
    "print(random.choice(pairs), input_lang.language, output_lang.language)\n",
    "input_lang, output_lang, pairs = read_data('eng', 'ita', False, verbose=False)\n",
    "print(random.choice(pairs), input_lang.language, output_lang.language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trim the dataset to contain only 10000 examples and only phrases with less than 10 words.\n",
    "This is done to reduce the training time and to make the model learn faster.\n",
    "If you have a better GPU, you can increase the number of examples and the length of the phrases,\n",
    "sadly we are GPU-Poor hahaha, maybe Dani and Joan can grab some from the CVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "MAX_PAIRS = 100000\n",
    "\n",
    "def filterPair(p):\n",
    "    return (len(p[0].split(' ')) and len(p[1].split(' '))) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def trim_dataset(pairs):\n",
    "    # Filter pairs using the filterPair condition and choosing 100000 random pairs\n",
    "    pairs = [pair for pair in pairs if filterPair(pair)]\n",
    "    return random.sample(pairs, MAX_PAIRS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-   Read text file and split into lines, split lines into pairs\n",
    "-   Normalize text, filter by length and content\n",
    "-   Make word lists from sentences in pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Data\n",
      "Read all the 345244 sentence pairs in the dataset\n",
      "Trimmed to 100000 sentence pairs using the trim_dataset function\n",
      "There are 9243 words in eng and 17037 words in ita\n",
      "['i appreciate all you did', 'apprezzo tutto quello che hai fatto']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1, lang2, reverse=False):\n",
    "    ''''\n",
    "    Prepare the data for training by reading the data, filtering the pairs and counting the words\n",
    "    Returns the input and output language instances and the processed pairs\n",
    "    '''\n",
    "    # Read the data\n",
    "    input_lang, output_lang, pairs = read_data(lang1, lang2, reverse, verbose=True)\n",
    "    print(\"Read all the %s sentence pairs in the dataset\" % len(pairs))\n",
    "    # Filter the pairs\n",
    "    pairs = trim_dataset(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs using the trim_dataset function\" % len(pairs))\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(f\"There are {input_lang.n_words} words in {input_lang.language} and {output_lang.n_words} words in {output_lang.language}\")\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('eng', 'ita')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Test and Validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training pairs is 70000\n",
      "         The number of validation pairs is 15000\n",
      "         The number of test pairs is 15000\n",
      "Training Pair: ['tom says he wants a puppy for christmas', 'tom dice che vuole un cucciolo per natale']\n",
      "Validation Pair: ['i m resting now', 'mi sto riposando ora']\n",
      "Test Pair: ['i met them', 'io le ho incontrate']\n"
     ]
    }
   ],
   "source": [
    "# Divide data into training, validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_pairs, test_val_pairs = train_test_split(pairs, test_size=0.3, random_state=42) #70% train, 30% test & val\n",
    "test_pairs, val_pairs = train_test_split(test_val_pairs, test_size=0.5, random_state=42) #15% test, 15% val\n",
    "\n",
    "#Check the amount of data in each set\n",
    "print(f\"The number of training pairs is {len(train_pairs)}\\n \\\n",
    "        The number of validation pairs is {len(val_pairs)}\\n \\\n",
    "        The number of test pairs is {len(test_pairs)}\")\n",
    "\n",
    "#Sample an example from the training set, validation set and test set\n",
    "print(f\"Training Pair: {random.choice(train_pairs)}\")\n",
    "print(f\"Validation Pair: {random.choice(val_pairs)}\")\n",
    "print(f\"Test Pair: {random.choice(test_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model\n",
    "\n",
    "The model is composed of an encoder and a decoder. The encoder reads the input sequence and outputs a context vector for each word in the input sequence. The decoder reads the context vector and generates the output sequence, hopefully translating the input sequence to the output sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.guru99.com/images/1/111318_0848_seq2seqSequ1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "The encoder of a seq2seq network is a RNN, in our case we'll use a GRU for the sake of simplicity.\n",
    "This GRU encoder outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    '''\n",
    "    EncoderRNN class to encode the input language, it uses an embedding layer and a GRU layer\n",
    "    basically it encodes the input language into a hidden state.\n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #Embedding layer to convert words to vectors of fixed size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        #GRU layer to encode the input language\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        #Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''Forward pass of the encoder'''\n",
    "        #Convert the input to embeddings and apply dropout\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #Pass the embeddings through the GRU layer and get the output and hidden state\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage of the EncoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor Shape: torch.Size([1, 10])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output Shape: torch.Size([1, 10, 256])\n",
      "Encoder Output: tensor([[[ 0.1310,  0.0854, -0.1898,  ..., -0.1377,  0.2110, -0.1113],\n",
      "         [ 0.0928, -0.0747, -0.5007,  ...,  0.1191, -0.0978, -0.2314],\n",
      "         [-0.2692, -0.1656, -0.3151,  ...,  0.1144, -0.0467, -0.2047],\n",
      "         ...,\n",
      "         [ 0.2188,  0.1493, -0.0403,  ..., -0.0857, -0.3381,  0.3317],\n",
      "         [ 0.0944, -0.0703, -0.4308,  ...,  0.3516, -0.1634,  0.1191],\n",
      "         [ 0.3241, -0.0082,  0.2145,  ...,  0.2565,  0.3634,  0.0795]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Hidden Shape: torch.Size([1, 1, 256])\n",
      "Encoder Hidden: tensor([[[ 0.3241, -0.0082,  0.2145,  0.1909,  0.0068, -0.6466,  0.2043,\n",
      "           0.3482, -0.2861, -0.2410, -0.3760, -0.6981,  0.0652, -0.3618,\n",
      "          -0.0979,  0.1486, -0.0119,  0.3534, -0.0866,  0.0455, -0.2180,\n",
      "           0.5206,  0.0580, -0.1590,  0.5506,  0.0749, -0.2723,  0.3532,\n",
      "           0.5387,  0.0152, -0.0071, -0.3579,  0.1241, -0.4210, -0.0879,\n",
      "          -0.0890, -0.2671, -0.4565,  0.1090,  0.0394,  0.1974,  0.1586,\n",
      "           0.2900, -0.3482,  0.5190,  0.1645,  0.0044,  0.0371, -0.2102,\n",
      "           0.3607,  0.6081, -0.0274, -0.2515,  0.1456,  0.2992,  0.3900,\n",
      "           0.3928,  0.5950, -0.2812, -0.0729,  0.2945, -0.1519,  0.0301,\n",
      "           0.2343, -0.1104,  0.2689, -0.2352, -0.3194, -0.1322, -0.5329,\n",
      "           0.4901, -0.2242,  0.2905, -0.3193,  0.3581, -0.4491, -0.1660,\n",
      "          -0.0617,  0.5039,  0.2493,  0.3603,  0.2518,  0.4896, -0.1821,\n",
      "          -0.3796,  0.2314,  0.1013, -0.1498, -0.5544, -0.1072, -0.1018,\n",
      "          -0.0892, -0.2948,  0.2089,  0.4501,  0.3145,  0.3399,  0.2611,\n",
      "           0.1710,  0.1839,  0.1630, -0.5538, -0.0063,  0.1555,  0.1112,\n",
      "           0.2450,  0.1221, -0.2328, -0.5413, -0.5354, -0.1928,  0.0185,\n",
      "          -0.1466, -0.1454,  0.4276, -0.1262, -0.4717,  0.4993,  0.3591,\n",
      "          -0.3640, -0.0893,  0.1950, -0.1876,  0.3725,  0.4462, -0.3915,\n",
      "          -0.2826, -0.3265, -0.0576,  0.1097,  0.0280,  0.3895, -0.3203,\n",
      "           0.0157,  0.2122,  0.1257, -0.0230, -0.2842,  0.2654, -0.0021,\n",
      "           0.3303,  0.1475,  0.3867,  0.0841,  0.2543, -0.2083, -0.5635,\n",
      "           0.1171, -0.3989,  0.1791,  0.2273, -0.0123, -0.5968, -0.5541,\n",
      "           0.0109,  0.1753,  0.2762, -0.2181, -0.3970,  0.3156,  0.3166,\n",
      "          -0.2053, -0.1744,  0.2349, -0.2971, -0.5827,  0.0470, -0.0397,\n",
      "          -0.2814,  0.1487,  0.0257, -0.0155, -0.5909, -0.0894, -0.0872,\n",
      "           0.0440,  0.0638, -0.3209,  0.1256,  0.2141, -0.5742, -0.0081,\n",
      "          -0.3754, -0.2735, -0.1883, -0.5951,  0.4420, -0.0560, -0.5468,\n",
      "          -0.3536,  0.0155, -0.4088,  0.6672,  0.2518, -0.1487, -0.3394,\n",
      "          -0.0862,  0.0731,  0.0931,  0.3376,  0.1493, -0.3289,  0.0039,\n",
      "           0.3394, -0.3622,  0.3593,  0.4073,  0.6865, -0.3610, -0.2103,\n",
      "           0.6752, -0.0188,  0.2185, -0.0632,  0.1062,  0.3800, -0.0106,\n",
      "           0.3649, -0.2032,  0.3963, -0.0108, -0.2620,  0.3682,  0.3147,\n",
      "          -0.3135,  0.2733, -0.0890, -0.1441,  0.0193, -0.3526, -0.0143,\n",
      "          -0.0105, -0.2213,  0.2182,  0.3012, -0.1311, -0.3431, -0.2579,\n",
      "          -0.0233, -0.5892,  0.0340,  0.0502, -0.0207,  0.0803,  0.2827,\n",
      "           0.2761, -0.1307, -0.3815, -0.2572,  0.1081, -0.1720, -0.4646,\n",
      "           0.1266,  0.2565,  0.3634,  0.0795]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Hidden size\n",
    "hidden_size = 256\n",
    "\n",
    "#Create an instance of the EncoderRNN \n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "\n",
    "#input tensor, it has a batch size of 1 and a sequence length of 10\n",
    "input_tensor = torch.randint(0, input_lang.n_words, (1, 10)).to(device) #random input tensor [1, 10] with values between 0 and input_lang.n_words\n",
    "\n",
    "#output and hidden state of the encoder after passing the input tensor\n",
    "output, hidden = encoder(input_tensor)\n",
    "\n",
    "#Print interesting information\n",
    "print(f\"Input Tensor Shape: {input_tensor.shape}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Output Shape: {output.shape}\")\n",
    "print(f\"Encoder Output: {output}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Hidden Shape: {hidden.shape}\")\n",
    "print(f\"Encoder Hidden: {hidden}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Decoder\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and\n",
    "outputs a sequence of words to create the translation, in this case we will use an Attention Decoder. In sequence-to-sequence models, an attention decoder lets the decoder focus on different parts of the encoder's output using a calculated set of \"attention weights\". These weights help create a weighted combination of encoder outputs (attn_applied), enhancing the decoder's ability to select accurate output words based on the input sequence's relevant parts. Here we use Bahdanau attention mechanism. The process involves training a feed-forward layer to calculate these weights, adjusted for varying sentence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    '''\n",
    "    The typical Badhanau Attention mechanism.\n",
    "        1. Calculate the attention scores by applying a linear layer to the encoder outputs and decoder hidden state\n",
    "        2. Apply a softmax to the scores to get the attention weights\n",
    "        3. Multiply the attention weights by the encoder outputs to get the context vector\n",
    "        4. Return the context vector and the attention weights\n",
    "    '''\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        #Linear layers to calculate the attention scores\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size) #W matrix [hidden_size x hidden_size]\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size) #U matrix [hidden_size x hidden_size]\n",
    "        self.Va = nn.Linear(hidden_size, 1) #V vector [hidden_size x 1]\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        #Get the sum of the projection of the query and keys\n",
    "        addition = self.Wa(query) + self.Ua(keys) #Addition shape is [batch_size x seq_len x hidden_size]\n",
    "        \n",
    "        #Apply a non-linearity to the sum (tanh in this case because we want to keep the values between -1 and 1)\n",
    "        activated_addition = torch.tanh(addition)#Activated addition shape is [batch_size x seq_len x hidden_size]\n",
    "        \n",
    "        #Get the attention scores by applying the V matrix to the activated addition\n",
    "        scores = self.Va(activated_addition) #Scores shape right now is [batch_size x seq_len x 1]\n",
    "        \n",
    "        #Squeeze the scores to remove the last dimension and unsqueeze the scores to add a dimension at index 1\n",
    "        scores = scores.squeeze(2).unsqueeze(1) #Scores shape is now [batch_size x 1 x seq_len]\n",
    "\n",
    "        #Apply a softmax to the scores to get the attention weights adding up to 1\n",
    "        weights = F.softmax(scores, dim=-1) #Weights shape is [batch_size x 1 x seq_len]\n",
    "        \n",
    "        #Multiply the weights by the keys to get the context vector (bmm stands for batch matrix multiplication)\n",
    "        context = torch.bmm(weights, keys) #Context shape is [batch_size x 1 x hidden_size]\n",
    "\n",
    "        #Return the context vector and the attention weights.\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    '''\n",
    "    Attention Decoder class to decode the encoder outputs and the hidden \n",
    "    state into the target language, hopefully making a good translation.\n",
    "    It uses an embedding layer, an attention layer and a GRU layer \n",
    "    (you could add more layers if you want to improve the model)\n",
    "    '''\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True) #2 * hidden_size because we concatenate the embeddings and context vector\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None): #encoder outputs and encoder hidden are returned by the encoder\n",
    "        '''\n",
    "        Forward takes care of the forward pass of the decoder, it loops over the whole sequence length,\n",
    "        translating one word at a time by using the step_forward function.\n",
    "        '''\n",
    "        #Get the batch size\n",
    "        batch_size = encoder_outputs.size(0) \n",
    "        \n",
    "        #Initialize the decoder input with the SOS token for each sentence in the batch\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        \n",
    "        #Initialize the decoder hidden state with the encoder hidden state \n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        #Initialize the decoder outputs and attention maps as empty lists\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            #Make a forward step in the decoder, get the output, hidden state and attention weights for the decoder\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            #Append the decoder output and attention weights to their respective lists\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            #If there is a target tensor, use it as the next input, otherwise use the decoder output\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1) #Get the index of the maximum value\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input, gradient is not computed for the input.\n",
    "\n",
    "        #Concatenate the decoder outputs and attention weights along the sequence length dimension\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) #Apply a log softmax to the decoder outputs\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        #Return the decoder outputs and attention weights\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        '''\n",
    "        forward_step takes care of the forward pass of the decoder for a single time step (i.e. a single word)\n",
    "        '''\n",
    "        #Get the embeddings of the input with the applied dropout\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        #Permute the hidden state to have the batch size as the first dimension\n",
    "        query = hidden.permute(1, 0, 2) #from [1, batch_size, hidden_size] to [batch_size, 1, hidden_size]\n",
    "        \n",
    "        #Get the context vector and attention weights by applying the attention mechanism (Bahdanau)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        \n",
    "        #Concatenate the embeddings and context vector along the hidden size dimension\n",
    "        input_gru = torch.cat((embedded, context), dim=2) #Concatenation shape is [batch_size x 1 x 2 * hidden_size]\n",
    "        \n",
    "        #Pass the concatenated tensor through the GRU layer, get the output and hidden state\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        \n",
    "        #Pass the output through a linear layer to get the decoder output\n",
    "        output = self.out(output) #Now shape is [batch_size x 1 x output_size] \n",
    "                                  #where output_size is the number of words in the output language (i.e. Vocabulary size)\n",
    "\n",
    "        #Return the decoder output, hidden state and attention weights\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage of the AttnDecoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Outputs Shape: torch.Size([1, 10, 17037])\n",
      "Decoder Hidden Shape: torch.Size([1, 1, 256])\n",
      "Attentions Shape: torch.Size([1, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "#Example usage of the AttnDecoderRNN\n",
    "\n",
    "#Create an instance of the AttnDecoderRNN\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "#Pass the encoder\n",
    "decoder_outputs, decoder_hidden, attentions = decoder(output, hidden)\n",
    "\n",
    "#Print interesting information\n",
    "print(f\"Decoder Outputs Shape: {decoder_outputs.shape}\")\n",
    "print(f\"Decoder Hidden Shape: {decoder_hidden.shape}\")\n",
    "print(f\"Attentions Shape: {attentions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Preparing Training Data\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the\n",
    "words in the input sentence) and target tensor (indexes of the words in\n",
    "the target sentence). While creating these vectors we will append the\n",
    "EOS token to both sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentence_to_indexes(lang, sentence):\n",
    "    '''Get the indexes of the words in the sentence using the language vocabulary'''\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def sentence_to_tensor(lang, sentence):\n",
    "    ''' Turn sentence into tensor of word indices and add EOS token'''\n",
    "    indexes = sentence_to_indexes(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def pair_to_tensor(pair):\n",
    "    ''' Get the input and target tensors from the pair of sentences'''\n",
    "    input_tensor = sentence_to_tensor(input_lang, pair[0])\n",
    "    target_tensor = sentence_to_tensor(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloaders(batch_size):\n",
    "    ''' Get the dataloaders for the training, validation and test sets'''\n",
    "    #Get the input and output languages and the pairs from the data\n",
    "    input_lang, output_lang, pairs = prepare_data('eng', 'ita', True) \n",
    "\n",
    "    # Splitting the data into train, validation, and test sets\n",
    "    train_pairs, test_val_pairs = train_test_split(pairs, test_size=0.3, random_state=42)\n",
    "    test_pairs, val_pairs = train_test_split(test_val_pairs, test_size=0.5, random_state=42)\n",
    "\n",
    "    def create_dataloader(pairs):\n",
    "        '''\n",
    "        Create a dataloader from the pairs by converting the sentences to tensors\n",
    "        and truncating the tensors to the maximum length if necessary\n",
    "        '''\n",
    "        #Get the amount of pairs\n",
    "        n = len(pairs) \n",
    "        \n",
    "        #Initialize the input and target tensors to zeros\n",
    "        input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)  # MAX_LENGTH = 10 for now (defined at the beginning of the notebook)\n",
    "        target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "        #Iterate over the pairs and convert the sentences to tensors\n",
    "        for idx, (inp, tgt) in enumerate(pairs):\n",
    "            #Get the indexes of the words in the sentences using the language vocabulary\n",
    "            inp_ids = sentence_to_indexes(input_lang, inp) \n",
    "            tgt_ids = sentence_to_indexes(output_lang, tgt)\n",
    "            \n",
    "            #Truncate to MAX_LENGTH-1 if necessary, which shouldn't be the case because all the filtered data is already less or equal than MAX_LENGTH\n",
    "            \n",
    "            if len(inp_ids) >= MAX_LENGTH: \n",
    "                inp_ids = inp_ids[:MAX_LENGTH-1]  # Truncate to MAX_LENGTH-1 if necessary\n",
    "                tgt_ids = tgt_ids[:MAX_LENGTH-1]  # Truncate to MAX_LENGTH-1 if necessary\n",
    "            inp_ids.append(EOS_token)\n",
    "            tgt_ids.append(EOS_token)\n",
    "            \n",
    "            #Add the tensors to the input and target tensors\n",
    "            input_ids[idx, :len(inp_ids)] = inp_ids \n",
    "            target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "        #Create a TensorDataset from the input and target tensors, TensorDataset is a PyTorch class to create datasets from tensors\n",
    "        dataset = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                                torch.LongTensor(target_ids).to(device))\n",
    "        \n",
    "        #Create a RandomSampler to sample the data randomly\n",
    "        sampler = RandomSampler(dataset)\n",
    "        \n",
    "        #Create a DataLoader from the dataset and the sampler\n",
    "        dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "        return dataloader\n",
    "\n",
    "    # Creating separate dataloaders for the training, testing, and validation sets, how do we ensure they are differen\n",
    "    train_dataloader = create_dataloader(train_pairs)\n",
    "    test_dataloader = create_dataloader(test_pairs)\n",
    "    val_dataloader = create_dataloader(val_pairs)\n",
    "    \n",
    "    #Return the input and output languages and the dataloaders for training, testing, and validation\n",
    "    return input_lang, output_lang, train_dataloader, test_dataloader, val_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage of the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "batch_size = 64\n",
    "input_lang, output_lang, train_dataloader, test_dataloader, val_dataloader = get_dataloaders(batch_size)\n",
    "\n",
    "print(f\"Number of training batches: {len(train_dataloader)}\")\n",
    "\n",
    "#Sample a batch from the training dataloader\n",
    "print(f\"Sample Batch: { next(iter(train_dataloader))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "To train the model, we start by passing the input sentence to the encoder, which saves all its outputs and the final hidden state. Then, the decoder starts with the <SOS> token as its initial input and uses the encoder’s last hidden state as its first hidden state.\n",
    "\n",
    "We use Teacher forcing which is a technique where the true target outputs are used as each subsequent input to the decoder, rather than the decoder's own predictions. This method helps the model train faster but can lead to instability when the model is used in practice, as noted in research. This happens because the model might learn to form correct grammar and structure by following the lead given by the initial words, but it might not learn to generate the sentence independently from the input translation.\n",
    "\n",
    "PyTorch's autograd system allows us to easily integrate teacher forcing randomly in training by using an if statement to decide when to apply it. We can then adjust the teacher_forcing_ratio to control how frequently teacher forcing is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, train=True):\n",
    "    '''\n",
    "    train_epoch function to train the encoder and decoder for one epoch\n",
    "    '''\n",
    "    #First check if we are training or evaluating\n",
    "    if train:\n",
    "        #Set the encoder and decoder to training mode\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "    else:\n",
    "        #Set the encoder and decoder to evaluation mode\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "    #initialize the total loss to 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    #iterate over the dataloader\n",
    "    for data in dataloader:\n",
    "        \n",
    "        #Get the input and target tensors from the data\n",
    "        input_tensor, target_tensor = data\n",
    "        \n",
    "        #Zero the gradients of the encoder and decoder for each batch\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        #Pass the input tensor through the encoder and get the outputs and hidden state\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        \n",
    "        #Pass the outputs of the encoder through the decoder and get\n",
    "        decoder_outputs, hidden, attn_weights = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "        \n",
    "        #Calculate the loss by comparing the decoder outputs and the target tensor\n",
    "        loss = criterion(decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1))\n",
    "        \n",
    "        if train:\n",
    "            #If training, backpropagate the loss and update the parameters, if evaluating, only accumulate the loss\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            \n",
    "        #Update the total loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    #Return the average loss for the epoch\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=1, log_wandb=True, save_models=True):\n",
    "    \n",
    "    #Initialize best_val_loss\n",
    "    best_val_loss = 10000\n",
    "    \n",
    "    #Initiaalize max_patience\n",
    "    max_patience = 5\n",
    "    \n",
    "    #Initialize the plot losses list\n",
    "    plot_losses = []\n",
    "\n",
    "    #Define the optimizer and the criterion\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    #Iterate over the epochs\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        #Train the model for one epoch\n",
    "        train_loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, train=True)\n",
    "        \n",
    "        #Evaluate the model for one epoch\n",
    "        val_loss = train_epoch(val_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, train=False)\n",
    "        \n",
    "        #Plot the losses\n",
    "        plot_losses.append((train_loss, val_loss))\n",
    "\n",
    "        if log_wandb:\n",
    "            #Log the losses to wandb\n",
    "            wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            #Print the losses and the time elapsed for every print_every epochs\n",
    "            print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            max_patience = 5\n",
    "            if save_models:\n",
    "                #Save the encoder and decoder models if val loss improved\n",
    "                torch.save(encoder.state_dict(), f\"models/MT_encoder_epoch_{epoch}.pt\")\n",
    "                torch.save(decoder.state_dict(), f\"models/MT_decoder_epoch_{epoch}.pt\")\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            max_patience -= 1\n",
    "            if max_patience == 0:\n",
    "                print(f\"Early stopping at epoch {epoch} due to non improvement in validation loss\")\n",
    "                break\n",
    "            \n",
    "\n",
    "    if log_wandb:\n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Data\n",
      "Read all the 345244 sentence pairs in the dataset\n",
      "Trimmed to 100000 sentence pairs using the trim_dataset function\n",
      "There are 17191 words in ita and 9461 words in eng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [00:58<1:16:59, 58.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 2.7421, Val Loss: 2.0388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [01:54<1:14:24, 57.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 1.7569, Val Loss: 1.5523\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "hidden_size = 128\n",
    "batch_size = 64\n",
    "\n",
    "input_lang, output_lang, train_dataloader, test_dataloader, val_dataloader = get_dataloaders(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, val_dataloader, encoder, decoder, n_epochs=80, learning_rate=0.001, log_wandb=True, save_models=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder\\'s predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder\\'s\n",
    "attention outputs for display later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence_to_tensor(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dropout layers to `eval` mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> tom made some bad investments\n",
      "= tom fece qualche cattivo investimento\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'made'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m decoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 3\u001b[0m evaluateRandomly(encoder, decoder)\n",
      "Cell \u001b[0;32mIn[79], line 6\u001b[0m, in \u001b[0;36mevaluateRandomly\u001b[0;34m(encoder, decoder, n)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m, pair[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m, pair[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m output_words, _ \u001b[38;5;241m=\u001b[39m evaluate(encoder, decoder, pair[\u001b[38;5;241m0\u001b[39m], input_lang, output_lang)\n\u001b[1;32m      7\u001b[0m output_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output_words)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, output_sentence)\n",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, input_lang, output_lang)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(encoder, decoder, sentence, input_lang, output_lang):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m         input_tensor \u001b[38;5;241m=\u001b[39m sentence_to_tensor(input_lang, sentence)\n\u001b[1;32m      5\u001b[0m         encoder_outputs, encoder_hidden \u001b[38;5;241m=\u001b[39m encoder(input_tensor)\n\u001b[1;32m      6\u001b[0m         decoder_outputs, decoder_hidden, decoder_attn \u001b[38;5;241m=\u001b[39m decoder(encoder_outputs, encoder_hidden)\n",
      "Cell \u001b[0;32mIn[57], line 5\u001b[0m, in \u001b[0;36msentence_to_tensor\u001b[0;34m(lang, sentence)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentence_to_tensor\u001b[39m(lang, sentence):\n\u001b[0;32m----> 5\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m sentence_to_indexes(lang, sentence)\n\u001b[1;32m      6\u001b[0m     indexes\u001b[38;5;241m.\u001b[39mappend(EOS_token)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(indexes, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m, in \u001b[0;36msentence_to_indexes\u001b[0;34m(lang, sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentence_to_indexes\u001b[39m(lang, sentence):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [lang\u001b[38;5;241m.\u001b[39mword2index[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentence_to_indexes\u001b[39m(lang, sentence):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [lang\u001b[38;5;241m.\u001b[39mword2index[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'made'"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Attention\n",
    "=====================\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable\n",
    "outputs. Because it is used to weight specific encoder outputs of the\n",
    "input sequence, we can imagine looking where the network is focused most\n",
    "at each time step.\n",
    "\n",
    "You could simply run `plt.matshow(attentions)` to see attention output\n",
    "displayed as a matrix. For a better viewing experience we will do the\n",
    "extra work of adding axes and labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = no\n",
      "output = no no longer no <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_955348/1563217870.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/tmp/ipykernel_955348/1563217870.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "=========\n",
    "\n",
    "-   Try with a different dataset\n",
    "    -   Another language pair\n",
    "    -   Human → Machine (e.g. IOT commands)\n",
    "    -   Chat → Response\n",
    "    -   Question → Answer\n",
    "-   Replace the embeddings with pretrained word embeddings such as\n",
    "    `word2vec` or `GloVe`\n",
    "-   Try with more layers, more hidden units, and more sentences. Compare\n",
    "    the training time and results.\n",
    "-   If you use a translation file where pairs have two of the same\n",
    "    phrase (`I am test \\t I am test`), you can use this as an\n",
    "    autoencoder. Try this:\n",
    "    -   Train as an autoencoder\n",
    "    -   Save only the Encoder network\n",
    "    -   Train a new Decoder for translation from there\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
