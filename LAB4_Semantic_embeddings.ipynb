{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 4 - Semantic Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 – Word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import spacy library and load the en_core_web_md model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spacy library\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the English model\n",
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show the word vector for “football”, how long is it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the representation of the word \"football\"\n",
    "football = nlp(\"football\")\n",
    "print(football.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Show the word vector for “frankfurteria”, how long is it?\n",
    "\n",
    "Only words in model’s vocabulary have vectors, the rest are called out-ofvocabulary (OOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the representation of the word \"frankfurteria\" and show the length of the vector\n",
    "\n",
    "vec_frankfurteria = nlp(\"frankfurteria\").vector\n",
    "\n",
    "print(vec_frankfurteria, \"\\nLenght of the vector:\", len(vec_frankfurteria))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see frankfurteria is an Out Of Vocabulary word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Check whether the word “flowers” is in the model vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the word \"flowers\" is in the vocabulary\n",
    "\n",
    "if \"flowers\" in nlp.vocab.strings:\n",
    "  print(\"The word 'flowers' is in the vocabulary\")\n",
    "\n",
    "else:\n",
    "  print(\"The word 'flowers' is not in the vocabulary\")\n",
    "\n",
    "#Get the representation of the word \"flowers\"\n",
    "#print(nlp(\"flowers\").vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a sentence including the word ”football”, and show the sentence vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Football is a great sport\"\n",
    "sent_vec = nlp(sentence).vector\n",
    "print(sent_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. How long is the sentence vector? How is it calculated?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLenght of the vector:\", len(sent_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the sentence have many words, the length is 300 because they do the average of the vectors of all the sentence \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 – Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define the two utterances “I visited Scotland” and “I went to Edinburgh”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt1 = \"I visited Scotland\"\n",
    "utt2 = \"I went to Edinburgh\"\n",
    "utt1_vec = nlp(utt1).vector\n",
    "utt2_vec = nlp(utt2).vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate the similarity between these two sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt1 = nlp(\"I visited Scotland\")\n",
    "utt2 = nlp(\"I went to Edinburgh\")\n",
    "\n",
    "utt1.similarity(utt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    " \n",
    " \n",
    "# compute cosine similarity\n",
    "cosine = np.dot(utt1_vec,utt2_vec)/(norm(utt1_vec)*norm(utt2_vec))\n",
    "print(\"The cosine similarity is:\",cosine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define two similar sentences and calculate their similarity,\n",
    "then define two very different sentences and calculate their similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities of 2 similar sentences\n",
    "sent_1 = \"I do not like football\"\n",
    "sent_2 = \"I hate soccer\"\n",
    "sent_1_vec = nlp(sent_1).vector\n",
    "sent_2_vec = nlp(sent_2).vector\n",
    "cosine = np.dot(sent_1_vec,sent_2_vec)/(norm(sent_1_vec)*norm(sent_2_vec))\n",
    "print(f\"The cosine similarity for sentences: 'I do not like football' and 'I hate soccer' is:\\n{cosine}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities of 2 dissimilar sentences\n",
    "sent_1 = \"I do not like football\"\n",
    "sent_2 = \"I love soccer\"\n",
    "sent_1_vec = nlp(sent_1).vector\n",
    "sent_2_vec = nlp(sent_2).vector\n",
    "cosine = np.dot(sent_1_vec,sent_2_vec)/(norm(sent_1_vec)*norm(sent_2_vec))\n",
    "print(f\"The cosine similarity for sentences: 'I do not like football' and 'I hate soccer' is:\\n{cosine}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Consider the following words [cat, dog, tiger, elephant, bird, monkey, lion, cheetah, burger, pizza, food, cheese, wine, salad, noodles, fruit, vegetables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_list = []\n",
    "word_list = [\"cat\", \"dog\", \"tiger\", \"elephant\", \"bird\", \"monkey\", \"lion\",\"cheetah\", \"burger\", \"pizza\", \"food\", \"cheese\", \"wine\", \"salad\", \"noodles\", \"fruit\", \"vegetables\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the word vector for every word\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_list:\n",
    "    embed_list.append(nlp(word).vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Apply a PCA, consider the first two components, and epresent the words in the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "pca = PCA(n_components=2)\n",
    "embed_pca = pca.fit_transform(embed_list)\n",
    "\n",
    "x = [vector[0] for vector in embed_pca] # x-axis\n",
    "y = [vector[1] for vector in embed_pca] # y-axis\n",
    "\n",
    "plt.scatter(x,y, marker='o') #\n",
    "for i, word in enumerate(word_list):\n",
    "    plt.annotate(word, (x[i], y[i]))\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#Print the amount of variance explained by each of the selected components\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"The amount of variance explained by each of the selected components is:\\n component 1: {var_explained[0]}\\n component 2: {var_explained[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the amount of variance explained by each of the selected components\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"The amount of variance explained by each of the selected components is:\\n component 1: {var_explained[0]}\\n component 2: {var_explained[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do it in 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 3D PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "embed_pca = pca.fit_transform(embed_list)\n",
    "\n",
    "x = [vector[0] for vector in embed_pca] # x-axis\n",
    "y = [vector[1] for vector in embed_pca] # y-axis\n",
    "z = [vector[2] for vector in embed_pca] # z-axis\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, marker='o')\n",
    "\n",
    "for i, word in enumerate(word_list):\n",
    "    ax.text(x[i], y[i], z[i], word)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#Print the amount of variance explained by each of the selected components\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"The amount of variance explained by each of the selected components is:\\n component 1: {var_explained[0]}\\n component 2: {var_explained[1]}\\n component 3: {var_explained[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the amount of variance explained by each of the selected components\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"The amount of variance explained by each of the selected components is:\\n component 1: {var_explained[0]}\\n component 2: {var_explained[1]}\\n component 3: {var_explained[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new set of words (at least 20 different words), and\n",
    "represent them in the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = ['Apple', 'Banana', 'Grapes', 'Pear', 'Orange', 'Melon', 'Tomato', 'pineaple', \n",
    "                'raspberry', 'watermelon', 'Information', 'Data', 'Bit', 'Computer', 'Mouse', \n",
    "                'Tower', 'Screen', 'Music', 'Network', 'Phone']\n",
    "embed_list1 =[]\n",
    "for word1 in common_words:\n",
    "    embed_list1.append(nlp(word1).vector)\n",
    "pca = PCA(n_components=2)\n",
    "embed_pca1 = pca.fit_transform(embed_list1)\n",
    "\n",
    "x = [vector1[0] for vector1 in embed_pca1] # x-axis\n",
    "y = [vector1[1] for vector1 in embed_pca1] # y-axis\n",
    "\n",
    "plt.scatter(x,y, marker='o') #\n",
    "for i, word1 in enumerate(common_words):\n",
    "    plt.annotate(word1, (x[i], y[i]))\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Print the amount of variance explained by each of the selected components\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"The amount of variance explained by each of the selected components is:\\n component 1: {var_explained[0]}\\n component 2: {var_explained[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the amount of variance explained by each of the selected components\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"The amount of variance explained by each of the selected components is:\\n component 1: {var_explained[0]}\\n component 2: {var_explained[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "common_words = ['Apple', 'Banana', 'Grapes', 'Pear', 'Orange', 'Melon', 'Tomato', 'pineaple', \n",
    "                'raspberry', 'watermelon', 'Information', 'Data', 'Bit', 'Computer', 'Mouse', \n",
    "                'Tower', 'Screen', 'Music', 'Network', 'Phone']\n",
    "# 3D PCA\n",
    "embed_list =[]\n",
    "for word in common_words:\n",
    "    embed_list.append(nlp(word).vector)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "embed_pca = pca.fit_transform(embed_list)\n",
    "\n",
    "x = [vector[0] for vector in embed_pca] # x-axis\n",
    "y = [vector[1] for vector in embed_pca] # y-axis\n",
    "z = [vector[2] for vector in embed_pca] # z-axis\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, marker='o')\n",
    "\n",
    "for i, word in enumerate(common_words):\n",
    "    ax.text(x[i], y[i], z[i], word)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#Print the amount of variance explained by each of the selected components\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"The amount of variance explained by each of the selected components is:\\n component 1: {var_explained[0]}\\n component 2: {var_explained[1]}\\n component 3: {var_explained[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained = pca.explained_variance_ratio_\n",
    "print(f\"The amount of variance explained by each of the selected components is:\\n component 1: {var_explained[0]}\\n component 2: {var_explained[1]}\\n component 3: {var_explained[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise IV – Categorizing text with semantic similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a set of sentences, e.g., “I purchased a science fiction book last week. I loved this fragrance: light, floral and feminine. I purchased a bottle of wine.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = nlp(\"I purchased a science fiction book last week. I loved this fragrance: light, floral and feminine. I purchased a bottle of wine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a keyword, e.g., perfume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = nlp(\"perfume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the similarity between each sentence and the keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity between the sentence and the keyword\n",
    "sent.similarity(keyword)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Could we filter out the sentences which are not related with the keyword?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter words that are not related with the sentence\n",
    "#filtered_sent = [word for word in sent if word.is_alpha and not word.is_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Alexa’s review dataset, and filter out the reviews\n",
    "which are not associated with the “music” property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Sandstone Fabric</td>\n",
       "      <td>Without having a cellphone, I cannot use many ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Heather Gray Fabric</td>\n",
       "      <td>looks great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Awesome device wish I bought one ages ago.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>love it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Perfect for kids, adults and everyone in betwe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>I do love these things, i have them running my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>4</td>\n",
       "      <td>29-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2684 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating       date             variation  \\\n",
       "0          5  31-Jul-18      Charcoal Fabric    \n",
       "1          5  31-Jul-18      Charcoal Fabric    \n",
       "2          4  31-Jul-18        Walnut Finish    \n",
       "6          3  31-Jul-18     Sandstone Fabric    \n",
       "8          5  30-Jul-18  Heather Gray Fabric    \n",
       "...      ...        ...                   ...   \n",
       "3143       5  30-Jul-18            Black  Dot   \n",
       "3144       5  30-Jul-18            Black  Dot   \n",
       "3145       5  30-Jul-18            Black  Dot   \n",
       "3147       5  30-Jul-18            Black  Dot   \n",
       "3149       4  29-Jul-18            Black  Dot   \n",
       "\n",
       "                                       verified_reviews  feedback  \n",
       "0                                         Love my Echo!         1  \n",
       "1                                             Loved it!         1  \n",
       "2     Sometimes while playing a game, you can answer...         1  \n",
       "6     Without having a cellphone, I cannot use many ...         1  \n",
       "8                                           looks great         1  \n",
       "...                                                 ...       ...  \n",
       "3143         Awesome device wish I bought one ages ago.         1  \n",
       "3144                                            love it         1  \n",
       "3145  Perfect for kids, adults and everyone in betwe...         1  \n",
       "3147  I do love these things, i have them running my...         1  \n",
       "3149                                               Good         1  \n",
       "\n",
       "[2684 rows x 5 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('contents/amazon_alexa.tsv', delimiter = '\\t')\n",
    "\n",
    "filtered_df = data[~data['verified_reviews'].str.lower().str.contains(\"music\", na= False)]\n",
    "\n",
    "filtered_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
