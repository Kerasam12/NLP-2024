{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 5. LSTM FOR TEXT CLASSIFICATION & SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Load the pipeline and the en_core_web_md modules\\n2. Show the components considered in the pipeline\\n3. Load the SA dataset from Campus Virtual\\n4. Explore the dataset to describe it\\n5. Add the text categorizer component (using a multilabel model) to the pipeline\\n6. Add two labels: positive and negative sentiments\\n7. Create the comments’ samples\\n8. Initialize the pipeline\\n9. Enable the text categorizer component to be trained\\n10. Create an optimizer object (resume_training) to keep weights of existing statistical\\nmodels\\n11. Set 5 training epochs, and loss values\\n12. Test new data'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"1. Load the pipeline and the en_core_web_md modules\n",
    "2. Show the components considered in the pipeline\n",
    "3. Load the SA dataset from Campus Virtual\n",
    "4. Explore the dataset to describe it\n",
    "5. Add the text categorizer component (using a multilabel model) to the pipeline\n",
    "6. Add two labels: positive and negative sentiments\n",
    "7. Create the comments’ samples\n",
    "8. Initialize the pipeline\n",
    "9. Enable the text categorizer component to be trained\n",
    "10. Create an optimizer object (resume_training) to keep weights of existing statistical\n",
    "models\n",
    "11. Set 5 training epochs, and loss values\n",
    "12. Test new data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the pipeline and the en_core_web_md modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "#Load the pipeline and the en_core_web_md modules\n",
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show the components considered in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "#Show the components considered in the pipeline\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the SA dataset from Campus Virtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the SA dataset from Campus Virtual\n",
    "import pandas as pd\n",
    "\n",
    "sadataset = pd.read_csv(\"./contents/SA_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Possible Spoilers**</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Read the book, forget the movie!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>**Possible Spoilers Ahead**</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a script, what a story, what a mess!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hope this group of film-makers never re-unites.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Sentiment\n",
       "0                              **Possible Spoilers**       1          0\n",
       "1                   Read the book, forget the movie!       2          0\n",
       "2                        **Possible Spoilers Ahead**       2          0\n",
       "3          What a script, what a story, what a mess!       2          0\n",
       "4  I hope this group of film-makers never re-unites.       1          0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore the dataset to describe it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Rating    Sentiment\n",
      "count  5000.000000  5000.000000\n",
      "mean      5.902200     0.550000\n",
      "std       3.653944     0.497543\n",
      "min       1.000000     0.000000\n",
      "25%       2.000000     0.000000\n",
      "50%       7.000000     1.000000\n",
      "75%      10.000000     1.000000\n",
      "max      10.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "#Explore the dataset to describe it\n",
    "print(sadataset.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "10    1385\n",
      "1     1061\n",
      "8      520\n",
      "9      472\n",
      "3      401\n",
      "4      401\n",
      "2      387\n",
      "7      373\n",
      "Name: count, dtype: int64\n",
      "Rating\n",
      "10    0.2770\n",
      "1     0.2122\n",
      "8     0.1040\n",
      "9     0.0944\n",
      "3     0.0802\n",
      "4     0.0802\n",
      "2     0.0774\n",
      "7     0.0746\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Get rating distribution\n",
    "rating_distribution = sadataset['Rating'].value_counts()\n",
    "print(rating_distribution)\n",
    "#Now print it in percentages \n",
    "rating_distribution = sadataset['Rating'].value_counts(normalize=True)\n",
    "print(rating_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Add the text categorizer component (using a multilabel model) to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'textcat']\n"
     ]
    }
   ],
   "source": [
    "# Add the text categorizer component (using a multilabel model) to the pipeline\n",
    "textcat= nlp.add_pipe(\"textcat\")\n",
    "\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Add two labels: positive and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add two labels: positive and negative sentiments\n",
    "nlp.get_pipe(\"textcat\").add_label(\"positive\")\n",
    "nlp.get_pipe(\"textcat\").add_label(\"negative\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create the comments’ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>I have only seen this once--in 1986, at an \"ar...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>This being my first John Carpenter film, I mus...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>This is kind of a weird movie, given that Sant...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Vic (Richard Dreyfuss) is a mob boss, leaving ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Yup, that's right folks, this is undoubtedly t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Rating  Sentiment\n",
       "4995  I have only seen this once--in 1986, at an \"ar...      10          1\n",
       "4996  This being my first John Carpenter film, I mus...       9          1\n",
       "4997  This is kind of a weird movie, given that Sant...       1          0\n",
       "4998  Vic (Richard Dreyfuss) is a mob boss, leaving ...       4          0\n",
       "4999  Yup, that's right folks, this is undoubtedly t...       1          0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sadataset['Review'].values\n",
    "y = sadataset['Sentiment'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "from spacy.training import Example\n",
    "\n",
    "def create_examples(X, y):\n",
    "    examples = []\n",
    "    for text, label in zip(X, y):\n",
    "        examples.append(Example.from_dict(nlp.make_doc(text), {'cats': {'positive': int(label), 'negative': int(not label)}}))\n",
    "    return examples\n",
    "\n",
    "train_examples = create_examples(X_train, y_train)\n",
    "test_examples = create_examples(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Initialize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy's Example class is used to create the training data\n",
    "from spacy.training.example import Example\n",
    "input = Example.from_dict(nlp.make_doc(\"This is a good product\"), {\"cats\": {\"positive\": 1, \"negative\": 0}})\n",
    "textcat.initialize(lambda: [input], nlp = nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Enable the text categorizer component to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create an optimizer object (resume_training) to keep weights of existing statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create an optimizer object (resume_training) to keep weights of existing statistical models\n",
    "from spacy.util import minibatch\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "\n",
    "optimizer = nlp.resume_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Set 5 training epochs, and loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "[E978] The Language.update method takes a list of Example objects, but got: {<class 'str'>}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      4\u001b[0m     dicti \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdicti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dicti)\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\spacy\\language.py:1176\u001b[0m, in \u001b[0;36mLanguage.update\u001b[1;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(examples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m losses\n\u001b[1;32m-> 1176\u001b[0m \u001b[43mvalidate_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLanguage.update\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m examples \u001b[38;5;241m=\u001b[39m _copy_examples(examples)\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sgd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\spacy\\training\\example.pyx:57\u001b[0m, in \u001b[0;36mspacy.training.example.validate_examples\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: [E978] The Language.update method takes a list of Example objects, but got: {<class 'str'>}"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Set 5 training epochs, and loss values\n",
    "num_epochs = 5\n",
    "for i in range(num_epochs):\n",
    "    dicti = {}\n",
    "    nlp.update(X_train, sgd=optimizer, losses=dicti, drop=0.2)\n",
    "    print(dicti)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Test new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POSITIVE': 0.5115741491317749, 'NEGATIVE': 0.4884258508682251}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test new data\n",
    "test_text = \"This movie sucked, you should not see it\"\n",
    "\n",
    "doc = nlp(test_text)\n",
    "doc.cats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POSITIVE': 0.36717143654823303, 'NEGATIVE': 0.6328285336494446}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_text = \"This movie was the best one I have ever seen, i loved it\"\n",
    "\n",
    "doc = nlp(test_text)\n",
    "doc.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
