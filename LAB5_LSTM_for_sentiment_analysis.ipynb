{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 5. LSTM FOR TEXT CLASSIFICATION & SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Load the pipeline and the en_core_web_md modules\\n2. Show the components considered in the pipeline\\n3. Load the SA dataset from Campus Virtual\\n4. Explore the dataset to describe it\\n5. Add the text categorizer component (using a multilabel model) to the pipeline\\n6. Add two labels: positive and negative sentiments\\n7. Create the comments’ samples\\n8. Initialize the pipeline\\n9. Enable the text categorizer component to be trained\\n10. Create an optimizer object (resume_training) to keep weights of existing statistical\\nmodels\\n11. Set 5 training epochs, and loss values\\n12. Test new data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"1. Load the pipeline and the en_core_web_md modules\n",
    "2. Show the components considered in the pipeline\n",
    "3. Load the SA dataset from Campus Virtual\n",
    "4. Explore the dataset to describe it\n",
    "5. Add the text categorizer component (using a multilabel model) to the pipeline\n",
    "6. Add two labels: positive and negative sentiments\n",
    "7. Create the comments’ samples\n",
    "8. Initialize the pipeline\n",
    "9. Enable the text categorizer component to be trained\n",
    "10. Create an optimizer object (resume_training) to keep weights of existing statistical\n",
    "models\n",
    "11. Set 5 training epochs, and loss values\n",
    "12. Test new data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the pipeline and the en_core_web_md modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "#Load the pipeline and the en_core_web_md modules\n",
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show the components considered in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "#Show the components considered in the pipeline\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the SA dataset from Campus Virtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the SA dataset from Campus Virtual\n",
    "import pandas as pd\n",
    "\n",
    "sadataset = pd.read_csv(\"./contents/SA_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Possible Spoilers**</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Read the book, forget the movie!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>**Possible Spoilers Ahead**</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a script, what a story, what a mess!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hope this group of film-makers never re-unites.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Sentiment\n",
       "0                              **Possible Spoilers**       1          0\n",
       "1                   Read the book, forget the movie!       2          0\n",
       "2                        **Possible Spoilers Ahead**       2          0\n",
       "3          What a script, what a story, what a mess!       2          0\n",
       "4  I hope this group of film-makers never re-unites.       1          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore the dataset to describe it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Rating    Sentiment\n",
      "count  5000.000000  5000.000000\n",
      "mean      5.902200     0.550000\n",
      "std       3.653944     0.497543\n",
      "min       1.000000     0.000000\n",
      "25%       2.000000     0.000000\n",
      "50%       7.000000     1.000000\n",
      "75%      10.000000     1.000000\n",
      "max      10.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "#Explore the dataset to describe it\n",
    "print(sadataset.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "10    1385\n",
      "1     1061\n",
      "8      520\n",
      "9      472\n",
      "3      401\n",
      "4      401\n",
      "2      387\n",
      "7      373\n",
      "Name: count, dtype: int64\n",
      "Rating\n",
      "10    0.2770\n",
      "1     0.2122\n",
      "8     0.1040\n",
      "9     0.0944\n",
      "3     0.0802\n",
      "4     0.0802\n",
      "2     0.0774\n",
      "7     0.0746\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Get rating distribution\n",
    "rating_distribution = sadataset['Rating'].value_counts()\n",
    "print(rating_distribution)\n",
    "#Now print it in percentages \n",
    "rating_distribution = sadataset['Rating'].value_counts(normalize=True)\n",
    "print(rating_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Add the text categorizer component (using a multilabel model) to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'textcat']\n"
     ]
    }
   ],
   "source": [
    "# Add the text categorizer component (using a multilabel model) to the pipeline\n",
    "nlp.add_pipe(\"textcat\")\n",
    "\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Add two labels: positive and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add two labels: positive and negative sentiments\n",
    "nlp.get_pipe(\"textcat\").add_label(\"positive\")\n",
    "nlp.get_pipe(\"textcat\").add_label(\"negative\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create the comments’ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>I have only seen this once--in 1986, at an \"ar...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>This being my first John Carpenter film, I mus...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>This is kind of a weird movie, given that Sant...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Vic (Richard Dreyfuss) is a mob boss, leaving ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Yup, that's right folks, this is undoubtedly t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Rating  Sentiment\n",
       "4995  I have only seen this once--in 1986, at an \"ar...      10          1\n",
       "4996  This being my first John Carpenter film, I mus...       9          1\n",
       "4997  This is kind of a weird movie, given that Sant...       1          0\n",
       "4998  Vic (Richard Dreyfuss) is a mob boss, leaving ...       4          0\n",
       "4999  Yup, that's right folks, this is undoubtedly t...       1          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This movie is funny in more ways than one. It\\'s got action. It\\'s got humour. It\\'s got attitude. It\\'s got Dolemite\\'s all girl army of kung-fu hos! And that\\'s just what the movie offers as a film. It\\'s also badly acted by some, the mic makes more than one cameo appearance, and some \"punches\" miss by feet. But when you make a movie this cool, who\\'s got time to pay attention to those \"details\"? This movie rocks. Rent it tonight, if you can find it... I had to buy it to see it, but I don\\'t regret it!',\n",
       "  {'cats': {'negative': False, 'positive': True}}),\n",
       " ('I am sick of series with young and clueless people, talking about their \"problems\" all the time, self centered, boring and absolutely annoying (Popular; Dawson\\'s Creek; Beverly Hills; etc). \"Hack\" is a breath of fresh air, with a great actor (David Morse), a completely different plot, credible people with REAL problems (thank God !!) and very, very good histories. I just love it!! I hope \"Hack\" will go on for a long time, because it is a great television series for grown up people, for a change.',\n",
       "  {'cats': {'negative': False, 'positive': True}}),\n",
       " ('This is a bizarre oddity, directed by the guy who edited \"The Texas Chainsaw Massacre.\" Chuck Conners gives a hilariously over-the-top performance as the owner of a roadside \"wax\" museum which our doomed teenagers happen to break down near. The wax figures look \"so real,\" one of the teen\\'s points out. Heh, heh, heh...Not so much a slasher film as a weird mix of psychological horror and old fashioned \"House of Wax\"-style terror. I can think of many, many horror films that are worse than this one.',\n",
       "  {'cats': {'negative': False, 'positive': True}}),\n",
       " (\"The songs are fantastic and the story-line is good. Like many other acting schools, mine also produced HAIR. For most hair production it's a golden opportunity to do nude, but my production was fully dressed... I don't think full frontal nudity in a movie or a play guarantees artistic quality... And so did the creators of the movie. The movie version is great with classic hits following each other while letting the plot develop to the chilling climax. A great cast of actors, dancers and singers.\",\n",
       "  {'cats': {'negative': False, 'positive': True}}),\n",
       " (\"Wow. I've never seen nor heard of this film. It just came on tv (2:00 am) and I am in complete awe. Setup: a bunch of rich fat cats are out golfing. One knocks a ball into the rough. It lands by a NINJA!!!! A tuxedoed man walks over to pick the ball up. The ninja grabs it. Crushes it in his hand. Man pulls gun. Ninja pulls blowgun. Ninja blows dart into gun barrel. GUN EXPLODES!!!! This is just the beginning of the greatness, people. Everyone must see this movie. 10 big ol fat stars from trusty.\",\n",
       "  {'cats': {'negative': False, 'positive': True}}),\n",
       " ('I have only seen this once--in 1986, at an \"artsy\" theater in Minneapolis...but I remember it like I saw it a thousand times this morning. Hilarious (\"Sawing for Teens\", playing Scrabble with all \"e\" tiles), beautifully animated (taking off her eyes, shaking them back into position, then putting them back on), and poignant (the end of the world, the pettiness of a snit)...Required viewing for the human race. Calling this simply a cartoon is like calling THE GREAT GATSBY nifty typing.',\n",
       "  {'cats': {'negative': False, 'positive': True}}),\n",
       " (\"This being my first John Carpenter film, I must say I was very impressed by The Thing. Right from the beginning, the film draws you in, and never lets up on the tension. The film's special effects and models hold up well even today. Other than Kurt Russell, I wasn't familiar with any of the cast members but they were all exceptional in imparting fear, paranoia, and the desperation to survive. The Universal DVD has a wealth of very interesting behind the scenes extras. Strongly recommended, 9/10.\",\n",
       "  {'cats': {'negative': False, 'positive': True}}),\n",
       " ('This is kind of a weird movie, given that Santa Claus lives on a cloud in outer space and fights against Satan and his minions...but it\\'s still kinda fun.It has some genuine laughs...whether all of them were intentional is certainly debatable, though. This movie is not good, but I can say I really enjoyed watching it.I would recommend this movie over \"Santa Claus Conquers the Martians\", \"Santa Claus\" with Dudley Moore and John Lithgow, or \"The Santa Clause\" with Tim Allen.',\n",
       "  {'cats': {'negative': True, 'positive': False}}),\n",
       " (\"Vic (Richard Dreyfuss) is a mob boss, leaving a mental institution, back to his world of gangsters. How can a director have a cast with Richard Dreyfuss, Ellen Barkin, Jeff Goldblum, Diane Lane (very gorgeous), Gabriel Byrne, Gregory Hines, Kyle MacLachlan, Burt Reynolds, Billy Idol and a make such a waste of time? This movie is a comedy that is not funny, having a constellation in the cast. My vote is four.Title (Brazil):' Prazer em Matar-te!' ('Pleasure in Killing You!')\",\n",
       "  {'cats': {'negative': True, 'positive': False}}),\n",
       " (\"Yup, that's right folks, this is undoubtedly the worst show in the history of television. If you want to watch a sad, lonely and unfunny hack comedian attempt to entertain the masses with a half hour of pale and tired social ramblings that your mildly retarded cousin commented on at the Thanksgiving dinner table then this might be the show for you. This is billed as edgy comedy my friends but to be honest this makes Tim Allen look like Richard Pryor. Avoid at all costs. Unless you're a masochist.\",\n",
       "  {'cats': {'negative': True, 'positive': False}})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the comments’ samples\n",
    "train_texts = sadataset[\"Review\"].values\n",
    "train_sentiments = sadataset[\"Sentiment\"].values\n",
    "train_labels = [{\"cats\": {\"negative\": label == 0,\n",
    "                          \"positive\": label == 1}} \n",
    "                for label in sadataset[\"Sentiment\"]]\n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "\n",
    "train_data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Initialize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.optimizers.Optimizer at 0x21a9534fa40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize the pipeline\n",
    "nlp.begin_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Enable the text categorizer component to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextCategorizer' object has no attribute 'begin_training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#enable the text categorizer to be trained\u001b[39;00m\n\u001b[0;32m      2\u001b[0m textcat \u001b[38;5;241m=\u001b[39m nlp\u001b[38;5;241m.\u001b[39mget_pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextcat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtextcat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_training\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TextCategorizer' object has no attribute 'begin_training'"
     ]
    }
   ],
   "source": [
    "#enable the text categorizer to be trained\n",
    "textcat = nlp.get_pipe(\"textcat\")\n",
    "textcat.begin_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create an optimizer object (resume_training) to keep weights of existing statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create an optimizer object (resume_training) to keep weights of existing statistical models\n",
    "from spacy.util import minibatch\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Set 5 training epochs, and loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot get dimension 'nO' for model 'sparse_linear': value unset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m         doc \u001b[38;5;241m=\u001b[39m nlp\u001b[38;5;241m.\u001b[39mmake_doc(texts[i])\n\u001b[0;32m     21\u001b[0m         example\u001b[38;5;241m.\u001b[39mappend(Example\u001b[38;5;241m.\u001b[39mfrom_dict(doc, labels[i]))\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(losses)\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\spacy\\language.py:1193\u001b[0m, in \u001b[0;36mLanguage.update\u001b[1;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline:\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;66;03m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1193\u001b[0m         proc\u001b[38;5;241m.\u001b[39mupdate(examples, sgd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, losses\u001b[38;5;241m=\u001b[39mlosses, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg[name])  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sgd \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1196\u001b[0m             name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude\n\u001b[0;32m   1197\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proc, ty\u001b[38;5;241m.\u001b[39mTrainableComponent)\n\u001b[0;32m   1198\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mis_trainable\n\u001b[0;32m   1199\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1200\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\spacy\\pipeline\\textcat.py:253\u001b[0m, in \u001b[0;36mTextCategorizer.update\u001b[1;34m(self, examples, drop, sgd, losses)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m losses\n\u001b[0;32m    252\u001b[0m set_dropout_rate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, drop)\n\u001b[1;32m--> 253\u001b[0m scores, bp_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43meg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43meg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m loss, d_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loss(examples, scores)\n\u001b[0;32m    255\u001b[0m bp_scores(d_scores)\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\model.py:328\u001b[0m, in \u001b[0;36mModel.begin_update\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbegin_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable[[OutT], InT]]:\n\u001b[0;32m    322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the model over a batch of data, returning the output and a\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;124;03m    callback to complete the backward pass. A tuple (Y, finish_update),\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    where Y is a batch of output data, and finish_update is a callback that\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    takes the gradient with respect to the output and an optimizer function,\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    and returns the gradient with respect to the input.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\concatenate.py:57\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\concatenate.py:57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\with_cpu.py:25\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model, X: Any, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Callable]:\n\u001b[1;32m---> 25\u001b[0m     cpu_outputs, backprop \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     gpu_outputs \u001b[38;5;241m=\u001b[39m _to_device(model\u001b[38;5;241m.\u001b[39mops, cpu_outputs)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_cpu_backprop\u001b[39m(d_outputs):\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\model.py:328\u001b[0m, in \u001b[0;36mModel.begin_update\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbegin_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable[[OutT], InT]]:\n\u001b[0;32m    322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the model over a batch of data, returning the output and a\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;124;03m    callback to complete the backward pass. A tuple (Y, finish_update),\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    where Y is a batch of output data, and finish_update is a callback that\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    takes the gradient with respect to the output and an optimizer function,\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    and returns the gradient with respect to the input.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\resizable.py:26\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m     25\u001b[0m     layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 26\u001b[0m     Y, callback \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dY: OutT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InT:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callback(dY)\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\sparselinear.pyx:58\u001b[0m, in \u001b[0;36mthinc.layers.sparselinear.forward\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\layers\\sparselinear.pyx:83\u001b[0m, in \u001b[0;36mthinc.layers.sparselinear._begin_cpu_update\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\thinc\\model.py:194\u001b[0m, in \u001b[0;36mModel.get_dim\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get dimension \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: value unset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot get dimension 'nO' for model 'sparse_linear': value unset"
     ]
    }
   ],
   "source": [
    "#Spacy's Example class is used to create the training data\n",
    "from spacy.training.example import Example\n",
    "\n",
    "#Set 5 training epochs, and loss values\n",
    "losses = {}\n",
    "\n",
    "for epoch in range(5):\n",
    "    random.shuffle(train_data)\n",
    "    # Create the batch generator with batch size = 8\n",
    "    batches = minibatch(train_data, size=8)\n",
    "    # Iterate through minibatches\n",
    "    for batch in batches:\n",
    "        # Each batch is a list of (text, label) but we need to\n",
    "        # send separate lists for texts and labels to update().\n",
    "        # This is a quick way to split a list of tuples into lists\n",
    "        texts, labels = zip(*batch) # Unzipping the batch\n",
    "        example = []\n",
    "        # Update the model with iterating each text and label in the batch\n",
    "        for i in range(len(texts)):\n",
    "            doc = nlp.make_doc(texts[i])\n",
    "            example.append(Example.from_dict(doc, labels[i]))\n",
    "        nlp.update(example, drop=0.3, losses=losses)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Test new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test new data\n",
    "test_text = \"This movie sucked\"\n",
    "\n",
    "doc = nlp(test_text)\n",
    "doc.cats\n",
    "\n",
    "test_text = \"This movie was the best one I have ever seen\"\n",
    "\n",
    "doc = nlp(test_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
