{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 5. LSTM FOR TEXT CLASSIFICATION & SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1. Load the pipeline and the en_core_web_md modules\n",
    "2. Show the components considered in the pipeline\n",
    "3. Load the SA dataset from Campus Virtual\n",
    "4. Explore the dataset to describe it\n",
    "5. Add the text categorizer component (using a multilabel model) to the pipeline\n",
    "6. Add two labels: positive and negative sentiments\n",
    "7. Create the comments’ samples\n",
    "8. Initialize the pipeline\n",
    "9. Enable the text categorizer component to be trained\n",
    "10. Create an optimizer object (resume_training) to keep weights of existing statistical\n",
    "models\n",
    "11. Set 5 training epochs, and loss values\n",
    "12. Test new data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the pipeline and the en_core_web_md modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "#Load the pipeline and the en_core_web_md modules\n",
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "#Show the components considered in the pipeline\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show the components considered in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
